{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77aacbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occipital</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Occipital</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occipital</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Occipital</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occipital</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177936</th>\n",
       "      <td>OvaScience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177937</th>\n",
       "      <td>OvaScience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177938</th>\n",
       "      <td>OvaScience</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177939</th>\n",
       "      <td>OvaScience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177940</th>\n",
       "      <td>OvaScience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177941 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company  Sentiment\n",
       "0        Occipital          1\n",
       "1        Occipital         -1\n",
       "2        Occipital          1\n",
       "3        Occipital          1\n",
       "4        Occipital          0\n",
       "...            ...        ...\n",
       "177936  OvaScience          1\n",
       "177937  OvaScience          1\n",
       "177938  OvaScience         -1\n",
       "177939  OvaScience          1\n",
       "177940  OvaScience          1\n",
       "\n",
       "[177941 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "data = pd.read_csv('eng_tweets_with_sent_RNN.csv')\n",
    "data.head()\n",
    "# Keeping only the neccessary columns\n",
    "# data = data[['text','sentiment']]\n",
    "\n",
    "data = data[['Company','Sentiment']]\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99aa4573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4449/4449 [==============================] - 384s 80ms/step - loss: 1.0302 - accuracy: 0.4968 - val_loss: 1.0181 - val_accuracy: 0.5037\n",
      "Epoch 2/100\n",
      "4449/4449 [==============================] - 238s 54ms/step - loss: 1.0162 - accuracy: 0.5026 - val_loss: 1.0159 - val_accuracy: 0.5051\n",
      "Epoch 3/100\n",
      "4449/4449 [==============================] - 234s 53ms/step - loss: 1.0127 - accuracy: 0.5036 - val_loss: 1.0165 - val_accuracy: 0.5016\n",
      "Epoch 4/100\n",
      "4449/4449 [==============================] - 238s 53ms/step - loss: 1.0102 - accuracy: 0.5051 - val_loss: 1.0160 - val_accuracy: 0.5029\n",
      "Epoch 5/100\n",
      "4449/4449 [==============================] - 233s 52ms/step - loss: 1.0088 - accuracy: 0.5053 - val_loss: 1.0158 - val_accuracy: 0.5032\n",
      "Epoch 6/100\n",
      "4449/4449 [==============================] - 196s 44ms/step - loss: 1.0076 - accuracy: 0.5067 - val_loss: 1.0186 - val_accuracy: 0.5029\n",
      "Epoch 7/100\n",
      "4449/4449 [==============================] - 191s 43ms/step - loss: 1.0064 - accuracy: 0.5069 - val_loss: 1.0176 - val_accuracy: 0.5040\n",
      "Epoch 8/100\n",
      "4449/4449 [==============================] - 199s 45ms/step - loss: 1.0056 - accuracy: 0.5068 - val_loss: 1.0177 - val_accuracy: 0.5044\n",
      "Epoch 9/100\n",
      "4449/4449 [==============================] - 201s 45ms/step - loss: 1.0054 - accuracy: 0.5066 - val_loss: 1.0177 - val_accuracy: 0.5017\n",
      "Epoch 10/100\n",
      "4449/4449 [==============================] - 193s 43ms/step - loss: 1.0048 - accuracy: 0.5069 - val_loss: 1.0168 - val_accuracy: 0.5033\n",
      "Epoch 11/100\n",
      "4449/4449 [==============================] - 192s 43ms/step - loss: 1.0048 - accuracy: 0.5063 - val_loss: 1.0217 - val_accuracy: 0.5017\n",
      "Epoch 12/100\n",
      "4449/4449 [==============================] - 196s 44ms/step - loss: 1.0039 - accuracy: 0.5073 - val_loss: 1.0196 - val_accuracy: 0.5026\n",
      "Epoch 13/100\n",
      "4449/4449 [==============================] - 193s 43ms/step - loss: 1.0037 - accuracy: 0.5076 - val_loss: 1.0213 - val_accuracy: 0.5038\n",
      "Epoch 14/100\n",
      "4449/4449 [==============================] - 191s 43ms/step - loss: 1.0035 - accuracy: 0.5071 - val_loss: 1.0201 - val_accuracy: 0.5034\n",
      "Epoch 15/100\n",
      "4449/4449 [==============================] - 192s 43ms/step - loss: 1.0028 - accuracy: 0.5079 - val_loss: 1.0227 - val_accuracy: 0.5008\n",
      "Epoch 16/100\n",
      "4449/4449 [==============================] - 187s 42ms/step - loss: 1.0029 - accuracy: 0.5081 - val_loss: 1.0195 - val_accuracy: 0.5035\n",
      "Epoch 17/100\n",
      "4449/4449 [==============================] - 181s 41ms/step - loss: 1.0031 - accuracy: 0.5075 - val_loss: 1.0207 - val_accuracy: 0.5019\n",
      "Epoch 18/100\n",
      "4449/4449 [==============================] - 189s 42ms/step - loss: 1.0032 - accuracy: 0.5072 - val_loss: 1.0223 - val_accuracy: 0.5020\n",
      "Epoch 19/100\n",
      "4449/4449 [==============================] - 192s 43ms/step - loss: 1.0024 - accuracy: 0.5086 - val_loss: 1.0222 - val_accuracy: 0.5009\n",
      "Epoch 20/100\n",
      "4449/4449 [==============================] - 188s 42ms/step - loss: 1.0027 - accuracy: 0.5075 - val_loss: 1.0202 - val_accuracy: 0.5022\n",
      "Epoch 21/100\n",
      "4449/4449 [==============================] - 191s 43ms/step - loss: 1.0027 - accuracy: 0.5079 - val_loss: 1.0207 - val_accuracy: 0.5013\n",
      "Epoch 22/100\n",
      "4449/4449 [==============================] - 190s 43ms/step - loss: 1.0026 - accuracy: 0.5074 - val_loss: 1.0195 - val_accuracy: 0.5032\n",
      "Epoch 23/100\n",
      "4449/4449 [==============================] - 190s 43ms/step - loss: 1.0023 - accuracy: 0.5084 - val_loss: 1.0204 - val_accuracy: 0.5036\n",
      "Epoch 24/100\n",
      "4449/4449 [==============================] - 189s 42ms/step - loss: 1.0025 - accuracy: 0.5078 - val_loss: 1.0217 - val_accuracy: 0.5043\n",
      "Epoch 25/100\n",
      "4449/4449 [==============================] - 189s 43ms/step - loss: 1.0018 - accuracy: 0.5078 - val_loss: 1.0242 - val_accuracy: 0.5031\n",
      "Epoch 26/100\n",
      "4449/4449 [==============================] - 189s 42ms/step - loss: 1.0020 - accuracy: 0.5085 - val_loss: 1.0214 - val_accuracy: 0.5014\n",
      "Epoch 27/100\n",
      "4449/4449 [==============================] - 197s 44ms/step - loss: 1.0023 - accuracy: 0.5077 - val_loss: 1.0233 - val_accuracy: 0.5010\n",
      "Epoch 28/100\n",
      "4449/4449 [==============================] - 189s 42ms/step - loss: 1.0022 - accuracy: 0.5076 - val_loss: 1.0198 - val_accuracy: 0.5029\n",
      "Epoch 29/100\n",
      "4449/4449 [==============================] - 185s 42ms/step - loss: 1.0019 - accuracy: 0.5083 - val_loss: 1.0230 - val_accuracy: 0.5017\n",
      "Epoch 30/100\n",
      "4449/4449 [==============================] - 164s 37ms/step - loss: 1.0024 - accuracy: 0.5078 - val_loss: 1.0231 - val_accuracy: 0.5025\n",
      "Epoch 31/100\n",
      "4449/4449 [==============================] - 101s 23ms/step - loss: 1.0026 - accuracy: 0.5076 - val_loss: 1.0234 - val_accuracy: 0.5012\n",
      "Epoch 32/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0021 - accuracy: 0.5082 - val_loss: 1.0258 - val_accuracy: 0.5029\n",
      "Epoch 33/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0020 - accuracy: 0.5089 - val_loss: 1.0252 - val_accuracy: 0.5013\n",
      "Epoch 34/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0024 - accuracy: 0.5076 - val_loss: 1.0228 - val_accuracy: 0.5026\n",
      "Epoch 35/100\n",
      "4449/4449 [==============================] - 98s 22ms/step - loss: 1.0019 - accuracy: 0.5078 - val_loss: 1.0236 - val_accuracy: 0.5016\n",
      "Epoch 36/100\n",
      "4449/4449 [==============================] - 96s 22ms/step - loss: 1.0020 - accuracy: 0.5085 - val_loss: 1.0225 - val_accuracy: 0.5022\n",
      "Epoch 37/100\n",
      "4449/4449 [==============================] - 96s 22ms/step - loss: 1.0020 - accuracy: 0.5081 - val_loss: 1.0238 - val_accuracy: 0.5025\n",
      "Epoch 38/100\n",
      "4449/4449 [==============================] - 87s 20ms/step - loss: 1.0016 - accuracy: 0.5087 - val_loss: 1.0235 - val_accuracy: 0.5025\n",
      "Epoch 39/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0022 - accuracy: 0.5085 - val_loss: 1.0256 - val_accuracy: 0.5007\n",
      "Epoch 40/100\n",
      "4449/4449 [==============================] - 97s 22ms/step - loss: 1.0019 - accuracy: 0.5080 - val_loss: 1.0234 - val_accuracy: 0.5033\n",
      "Epoch 41/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0020 - accuracy: 0.5081 - val_loss: 1.0241 - val_accuracy: 0.5022\n",
      "Epoch 42/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0023 - accuracy: 0.5085 - val_loss: 1.0254 - val_accuracy: 0.5005\n",
      "Epoch 43/100\n",
      "4449/4449 [==============================] - 94s 21ms/step - loss: 1.0020 - accuracy: 0.5087 - val_loss: 1.0280 - val_accuracy: 0.4992\n",
      "Epoch 44/100\n",
      "4449/4449 [==============================] - 91s 20ms/step - loss: 1.0018 - accuracy: 0.5081 - val_loss: 1.0231 - val_accuracy: 0.5028\n",
      "Epoch 45/100\n",
      "4449/4449 [==============================] - 91s 21ms/step - loss: 1.0015 - accuracy: 0.5084 - val_loss: 1.0236 - val_accuracy: 0.5038\n",
      "Epoch 46/100\n",
      "4449/4449 [==============================] - 92s 21ms/step - loss: 1.0021 - accuracy: 0.5090 - val_loss: 1.0233 - val_accuracy: 0.5005\n",
      "Epoch 47/100\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: 1.0017 - accuracy: 0.5080 - val_loss: 1.0251 - val_accuracy: 0.5024\n",
      "Epoch 48/100\n",
      "4449/4449 [==============================] - 89s 20ms/step - loss: 1.0025 - accuracy: 0.5077 - val_loss: 1.0241 - val_accuracy: 0.5026\n",
      "Epoch 49/100\n",
      "4449/4449 [==============================] - 90s 20ms/step - loss: 1.0018 - accuracy: 0.5081 - val_loss: 1.0261 - val_accuracy: 0.5022\n",
      "Epoch 50/100\n",
      "4449/4449 [==============================] - 92s 21ms/step - loss: 1.0018 - accuracy: 0.5088 - val_loss: 1.0261 - val_accuracy: 0.5002\n",
      "Epoch 51/100\n",
      "4449/4449 [==============================] - 92s 21ms/step - loss: 1.0016 - accuracy: 0.5087 - val_loss: 1.0282 - val_accuracy: 0.5023\n",
      "Epoch 52/100\n",
      "4449/4449 [==============================] - 95s 21ms/step - loss: 1.0021 - accuracy: 0.5086 - val_loss: 1.0245 - val_accuracy: 0.5025\n",
      "Epoch 53/100\n",
      "4449/4449 [==============================] - 93s 21ms/step - loss: 1.0017 - accuracy: 0.5091 - val_loss: 1.0270 - val_accuracy: 0.5007\n",
      "Epoch 54/100\n",
      "4449/4449 [==============================] - 102s 23ms/step - loss: 1.0019 - accuracy: 0.5082 - val_loss: 1.0241 - val_accuracy: 0.5033\n",
      "Epoch 55/100\n",
      "4449/4449 [==============================] - 105s 24ms/step - loss: 1.0014 - accuracy: 0.5085 - val_loss: 1.0271 - val_accuracy: 0.5023\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4449/4449 [==============================] - 103s 23ms/step - loss: 1.0020 - accuracy: 0.5083 - val_loss: 1.0253 - val_accuracy: 0.5019\n",
      "Epoch 57/100\n",
      "4449/4449 [==============================] - 112s 25ms/step - loss: 1.0015 - accuracy: 0.5085 - val_loss: 1.0269 - val_accuracy: 0.5009\n",
      "Epoch 58/100\n",
      "4449/4449 [==============================] - 110s 25ms/step - loss: 1.0023 - accuracy: 0.5076 - val_loss: 1.0266 - val_accuracy: 0.5013\n",
      "Epoch 59/100\n",
      "4449/4449 [==============================] - 108s 24ms/step - loss: 1.0016 - accuracy: 0.5082 - val_loss: 1.0281 - val_accuracy: 0.5011\n",
      "Epoch 60/100\n",
      "4449/4449 [==============================] - 113s 25ms/step - loss: 1.0018 - accuracy: 0.5086 - val_loss: 1.0269 - val_accuracy: 0.5009\n",
      "Epoch 61/100\n",
      "4449/4449 [==============================] - 109s 25ms/step - loss: 1.0017 - accuracy: 0.5083 - val_loss: 1.0269 - val_accuracy: 0.5015\n",
      "Epoch 62/100\n",
      "4449/4449 [==============================] - 123s 28ms/step - loss: 1.0015 - accuracy: 0.5091 - val_loss: 1.0274 - val_accuracy: 0.5011\n",
      "Epoch 63/100\n",
      "4449/4449 [==============================] - 119s 27ms/step - loss: 1.0017 - accuracy: 0.5090 - val_loss: 1.0279 - val_accuracy: 0.5004\n",
      "Epoch 64/100\n",
      "4449/4449 [==============================] - 120s 27ms/step - loss: 1.0014 - accuracy: 0.5086 - val_loss: 1.0260 - val_accuracy: 0.5022\n",
      "Epoch 65/100\n",
      "4449/4449 [==============================] - 125s 28ms/step - loss: 1.0016 - accuracy: 0.5084 - val_loss: 1.0271 - val_accuracy: 0.5010\n",
      "Epoch 66/100\n",
      "4449/4449 [==============================] - 124s 28ms/step - loss: 1.0017 - accuracy: 0.5080 - val_loss: 1.0238 - val_accuracy: 0.5021\n",
      "Epoch 67/100\n",
      "4449/4449 [==============================] - 125s 28ms/step - loss: 1.0016 - accuracy: 0.5086 - val_loss: 1.0290 - val_accuracy: 0.5009\n",
      "Epoch 68/100\n",
      "4449/4449 [==============================] - 124s 28ms/step - loss: 1.0020 - accuracy: 0.5080 - val_loss: 1.0289 - val_accuracy: 0.5017\n",
      "Epoch 69/100\n",
      "4449/4449 [==============================] - 126s 28ms/step - loss: 1.0020 - accuracy: 0.5087 - val_loss: 1.0288 - val_accuracy: 0.5016\n",
      "Epoch 70/100\n",
      "4449/4449 [==============================] - 130s 29ms/step - loss: 1.0018 - accuracy: 0.5084 - val_loss: 1.0301 - val_accuracy: 0.5006\n",
      "Epoch 71/100\n",
      "4449/4449 [==============================] - 135s 30ms/step - loss: 1.0012 - accuracy: 0.5081 - val_loss: 1.0304 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "4449/4449 [==============================] - 129s 29ms/step - loss: 1.0022 - accuracy: 0.5082 - val_loss: 1.0277 - val_accuracy: 0.5011\n",
      "Epoch 73/100\n",
      "4449/4449 [==============================] - 126s 28ms/step - loss: 1.0022 - accuracy: 0.5085 - val_loss: 1.0253 - val_accuracy: 0.5013\n",
      "Epoch 74/100\n",
      "4449/4449 [==============================] - 127s 29ms/step - loss: 1.0022 - accuracy: 0.5085 - val_loss: 1.0243 - val_accuracy: 0.5008\n",
      "Epoch 75/100\n",
      "4449/4449 [==============================] - 128s 29ms/step - loss: 1.0021 - accuracy: 0.5086 - val_loss: 1.0240 - val_accuracy: 0.5020\n",
      "Epoch 76/100\n",
      "4449/4449 [==============================] - 128s 29ms/step - loss: 1.0015 - accuracy: 0.5088 - val_loss: 1.0261 - val_accuracy: 0.5018\n",
      "Epoch 77/100\n",
      "4449/4449 [==============================] - 118s 27ms/step - loss: 1.0020 - accuracy: 0.5083 - val_loss: 1.0244 - val_accuracy: 0.5018\n",
      "Epoch 78/100\n",
      "4449/4449 [==============================] - 117s 26ms/step - loss: 1.0019 - accuracy: 0.5088 - val_loss: 1.0278 - val_accuracy: 0.5011\n",
      "Epoch 79/100\n",
      "4449/4449 [==============================] - 116s 26ms/step - loss: 1.0021 - accuracy: 0.5080 - val_loss: 1.0229 - val_accuracy: 0.5020\n",
      "Epoch 80/100\n",
      "4449/4449 [==============================] - 115s 26ms/step - loss: 1.0019 - accuracy: 0.5085 - val_loss: 1.0271 - val_accuracy: 0.5035\n",
      "Epoch 81/100\n",
      "4449/4449 [==============================] - 115s 26ms/step - loss: 1.0022 - accuracy: 0.5081 - val_loss: 1.0262 - val_accuracy: 0.5023\n",
      "Epoch 82/100\n",
      "4449/4449 [==============================] - 116s 26ms/step - loss: 1.0029 - accuracy: 0.5079 - val_loss: 1.0238 - val_accuracy: 0.5026\n",
      "Epoch 83/100\n",
      "4449/4449 [==============================] - 117s 26ms/step - loss: 1.0025 - accuracy: 0.5080 - val_loss: 1.0258 - val_accuracy: 0.5015\n",
      "Epoch 84/100\n",
      "4449/4449 [==============================] - 115s 26ms/step - loss: 1.0023 - accuracy: 0.5081 - val_loss: 1.0265 - val_accuracy: 0.5039\n",
      "Epoch 85/100\n",
      "4449/4449 [==============================] - 117s 26ms/step - loss: 1.0022 - accuracy: 0.5077 - val_loss: 1.0249 - val_accuracy: 0.5027\n",
      "Epoch 86/100\n",
      "4449/4449 [==============================] - 117s 26ms/step - loss: 1.0020 - accuracy: 0.5089 - val_loss: 1.0309 - val_accuracy: 0.5025\n",
      "Epoch 87/100\n",
      "4449/4449 [==============================] - 155s 35ms/step - loss: 1.0022 - accuracy: 0.5081 - val_loss: 1.0236 - val_accuracy: 0.5025\n",
      "Epoch 88/100\n",
      "4449/4449 [==============================] - 124s 28ms/step - loss: 1.0024 - accuracy: 0.5080 - val_loss: 1.0256 - val_accuracy: 0.5020\n",
      "Epoch 89/100\n",
      "4449/4449 [==============================] - 122s 27ms/step - loss: 1.0020 - accuracy: 0.5081 - val_loss: 1.0248 - val_accuracy: 0.5023\n",
      "Epoch 90/100\n",
      "4449/4449 [==============================] - 118s 26ms/step - loss: 1.0026 - accuracy: 0.5077 - val_loss: 1.0261 - val_accuracy: 0.5026\n",
      "Epoch 91/100\n",
      "4449/4449 [==============================] - 123s 28ms/step - loss: 1.0020 - accuracy: 0.5086 - val_loss: 1.0286 - val_accuracy: 0.5018\n",
      "Epoch 92/100\n",
      "4449/4449 [==============================] - 123s 28ms/step - loss: 1.0019 - accuracy: 0.5080 - val_loss: 1.0271 - val_accuracy: 0.5013\n",
      "Epoch 93/100\n",
      "4449/4449 [==============================] - 122s 28ms/step - loss: 1.0018 - accuracy: 0.5093 - val_loss: 1.0250 - val_accuracy: 0.5016\n",
      "Epoch 94/100\n",
      "4449/4449 [==============================] - 150s 34ms/step - loss: 1.0026 - accuracy: 0.5080 - val_loss: 1.0245 - val_accuracy: 0.5017\n",
      "Epoch 95/100\n",
      "4449/4449 [==============================] - 168s 38ms/step - loss: 1.0024 - accuracy: 0.5091 - val_loss: 1.0237 - val_accuracy: 0.5021\n",
      "Epoch 96/100\n",
      "4449/4449 [==============================] - 172s 39ms/step - loss: 1.0024 - accuracy: 0.5078 - val_loss: 1.0252 - val_accuracy: 0.5010\n",
      "Epoch 97/100\n",
      "4449/4449 [==============================] - 171s 38ms/step - loss: 1.0025 - accuracy: 0.5087 - val_loss: 1.0254 - val_accuracy: 0.5030\n",
      "Epoch 98/100\n",
      "4449/4449 [==============================] - 175s 39ms/step - loss: 1.0022 - accuracy: 0.5080 - val_loss: 1.0244 - val_accuracy: 0.5034\n",
      "Epoch 99/100\n",
      "4449/4449 [==============================] - 158s 36ms/step - loss: 1.0024 - accuracy: 0.5083 - val_loss: 1.0253 - val_accuracy: 0.5016\n",
      "Epoch 100/100\n",
      "4449/4449 [==============================] - 134s 30ms/step - loss: 1.0019 - accuracy: 0.5090 - val_loss: 1.0245 - val_accuracy: 0.5006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29626d1b820>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this Bidirectional LSTM model, we have replaced the LSTM layer from the previous model with a Bidirectional LSTM layer. The Bidirectional LSTM layer processes the input sequence in both forward and backward directions, which can capture dependencies in the sequence more effectively. We have also added a second dense layer after the Bidirectional LSTM layer to increase the model capacity, and a Dropout layer to reduce overfitting.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "# Load the data\n",
    "#data = pd.read_csv('path/to/data.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "data['Company'] = data['Company'].apply(lambda x: x.lower())\n",
    "data['Company'] = data['Company'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=2000, split=' ')\n",
    "tokenizer.fit_on_texts(train_data['Company'].values)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Company'].values)\n",
    "X_train = pad_sequences(X_train)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Company'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=X_train.shape[1])\n",
    "\n",
    "# Categorize the sentiment labels\n",
    "y_train = train_data['Sentiment'].apply(lambda x: 0 if x < 0 else (1 if x == 0 else 2))\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = test_data['Sentiment'].apply(lambda x: 0 if x < 0 else (1 if x == 0 else 2))\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 128, input_length=X_train.shape[1]))\n",
    "model.add(Bidirectional(LSTM(196, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3ac09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5005760192871094\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95668b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113/1113 [==============================] - 7s 7ms/step\n",
      "Sentiment_Pred   -1    0    1\n",
      "Company                      \n",
      "140proof        0.0  0.0  1.0\n",
      "1stdibs         0.0  0.0  1.0\n",
      "2c2p            0.0  0.0  1.0\n",
      "2tor            0.0  0.0  1.0\n",
      "365datacenters  0.0  0.0  1.0\n",
      "...             ...  ...  ...\n",
      "zya             0.0  0.0  1.0\n",
      "zymesolutions   0.0  1.0  0.0\n",
      "zymeworks       0.0  1.0  0.0\n",
      "zyncro          0.0  0.0  1.0\n",
      "zynstra         0.0  0.0  1.0\n",
      "\n",
      "[1714 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted sentiment for each company in the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted sentiment probabilities to sentiment labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "sentiment_labels = ['-1', '0', '1']\n",
    "y_pred_sentiments = [sentiment_labels[i] for i in y_pred_labels]\n",
    "\n",
    "# Add the predicted sentiment labels to the test data\n",
    "test_data['Sentiment_Pred'] = y_pred_sentiments\n",
    "\n",
    "# Group the test data by company and calculate the overall sentiment for each company\n",
    "company_sentiments = test_data.groupby('Company')['Sentiment_Pred'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Print the overall sentiment for each company\n",
    "print(company_sentiments)\n",
    "# Save the company_sentiments DataFrame to a CSV file\n",
    "company_sentiments.to_csv('Company_Overall_Sentiment.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd3fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Company   -1    0    1 Series_Type\n",
      "0  140proof  0.0  0.0  1.0    Series_A\n",
      "1      2c2p  0.0  0.0  1.0    Series_C\n",
      "2      36kr  0.0  0.0  1.0    Series_C\n",
      "3     4home  0.0  0.0  1.0    Series_A\n",
      "4   6fusion  0.0  0.0  1.0    Series_B\n"
     ]
    }
   ],
   "source": [
    "# read in the two dataframes\n",
    "df1 = pd.read_csv('Company_Overall_Sentiment.csv')\n",
    "df2 = pd.read_csv('Company_Series.csv')\n",
    "\n",
    "# merge the dataframes based on the common column \"company\"\n",
    "merged_df = pd.merge(df1, df2, on='Company')\n",
    "\n",
    "# view the merged dataframe\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf4b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('FINAL_RESULT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449feca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3543ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
